{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b1b48f4-2c83-4f2a-adbb-5fe095500249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2eed73-6e8c-45c2-a11a-d57fb0a1a884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.12.0+cu116)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.26.5)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.3.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.28.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8884c367-127e-4a25-a4b9-45c69ffe74a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Grab a GPU if there is one\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using {} device: {}\".format(device, torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be686fbf-4013-47cd-9c93-86982e08d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (406, 3, 300), Train label shape: (406,)\n",
      "Valid data shape: (102, 3, 300), Valid label shape: (102,)\n",
      "Test data shape: (127, 3, 300), Test label shape: (127,)\n",
      "Scaled Train data shape: (406, 3, 300)\n",
      "Scaled Valid data shape: (102, 3, 300)\n",
      "Scaled Test data shape: (127, 3, 300)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "fold_pamap = \"../down_stream_dataset/adl_dataset/\"\n",
    "train_xyz = np.load(f\"{fold_pamap}x_train.npy\")\n",
    "valid_xyz = np.load(f\"{fold_pamap}x_valid.npy\")\n",
    "test_xyz = np.load(f\"{fold_pamap}x_test.npy\")\n",
    "train_label = np.load(f\"{fold_pamap}y_train.npy\")\n",
    "valid_label = np.load(f\"{fold_pamap}y_valid.npy\")\n",
    "test_label = np.load(f\"{fold_pamap}y_test.npy\")\n",
    "\n",
    "# データの形を確認\n",
    "print(f\"Train data shape: {train_xyz.shape}, Train label shape: {train_label.shape}\")\n",
    "print(f\"Valid data shape: {valid_xyz.shape}, Valid label shape: {valid_label.shape}\")\n",
    "print(f\"Test data shape: {test_xyz.shape}, Test label shape: {test_label.shape}\")\n",
    "\n",
    "# 各データセットを個別に標準化\n",
    "scaler_train = StandardScaler()\n",
    "scaler_valid = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "# train_xyz の標準化\n",
    "train_xyz_reshaped = train_xyz.reshape(-1, train_xyz.shape[-1])  # 2Dに変換\n",
    "scaled_train_xyz = scaler_train.fit_transform(train_xyz_reshaped)  # 標準化\n",
    "scaled_train_xyz = scaled_train_xyz.reshape(train_xyz.shape)  # 元の形に戻す\n",
    "\n",
    "# valid_xyz の標準化\n",
    "valid_xyz_reshaped = valid_xyz.reshape(-1, valid_xyz.shape[-1])  # 2Dに変換\n",
    "scaled_valid_xyz = scaler_valid.fit_transform(valid_xyz_reshaped)  # 標準化\n",
    "scaled_valid_xyz = scaled_valid_xyz.reshape(valid_xyz.shape)  # 元の形に戻す\n",
    "\n",
    "# test_xyz の標準化\n",
    "test_xyz_reshaped = test_xyz.reshape(-1, test_xyz.shape[-1])  # 2Dに変換\n",
    "scaled_test_xyz = scaler_test.fit_transform(test_xyz_reshaped)  # 標準化\n",
    "scaled_test_xyz = scaled_test_xyz.reshape(test_xyz.shape)  # 元の形に戻す\n",
    "\n",
    "# 各データセットの形状を再確認\n",
    "print(f\"Scaled Train data shape: {scaled_train_xyz.shape}\")\n",
    "print(f\"Scaled Valid data shape: {scaled_valid_xyz.shape}\")\n",
    "print(f\"Scaled Test data shape: {scaled_test_xyz.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1045eac1-6e84-4021-9b27-b071a815bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    186\n",
      "1     62\n",
      "2     58\n",
      "3     54\n",
      "0     46\n",
      "dtype: int64\n",
      "4    51\n",
      "1    25\n",
      "3    22\n",
      "2    19\n",
      "0    10\n",
      "dtype: int64\n",
      "4    42\n",
      "1    18\n",
      "3    17\n",
      "2    15\n",
      "0    10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(train_label).value_counts())\n",
    "print(pd.Series(test_label).value_counts())\n",
    "print(pd.Series(valid_label).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f925f26-d510-45bc-8067-61edb2bae047",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xyz = scaled_train_xyz\n",
    "valid_xyz = scaled_valid_xyz\n",
    "test_xyz = scaled_test_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9efe0669-94a3-4eab-83c9-29e56e96e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        super().__init__()\n",
    "        self._data = data \n",
    "        self._labels = labels  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self._data[idx], dtype=torch.float32), torch.tensor(self._labels[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df415d88-35f1-4dd1-bd09-efa24328aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = torch.tensor(train_label, dtype=torch.long)\n",
    "test_label = torch.tensor(test_label, dtype=torch.long)\n",
    "valid_label = torch.tensor(valid_label, dtype=torch.long)\n",
    "\n",
    "train_label = train_label - train_label.min()\n",
    "test_label = test_label - test_label.min()\n",
    "valid_label = valid_label - valid_label.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ef86a9-ca23-4668-9dda-aea248a47fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ClassificationDataset(train_xyz, train_label)\n",
    "test_dataset = ClassificationDataset(test_xyz, test_label)\n",
    "valid_dataset = ClassificationDataset(valid_xyz, valid_label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35683169-71d7-4baa-9862-0e3f55f35e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(train_label))\n",
    "pretrained_model = 'path/roberta_300.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0701d8d9-a92c-400e-bd6d-61b5a97185bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoBertaModelCustom2(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Linear(in_features=300, out_features=768, bias=True)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=768, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from Roberta import RoBertaModelCustom2\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaModel\n",
    "from transformers import RobertaConfig, TrainingArguments, Trainer\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "best_model_path = 'path/roberta_300.pth'\n",
    "\n",
    "# モデル構造を再定義\n",
    "config = RobertaConfig()\n",
    "model = RoBertaModelCustom2(config, num_sensor_dims=300)\n",
    "\n",
    "# 重みのロード\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c54e7fd0-de5e-467b-b1f5-41a91cc2457d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a14e3d13-cc7c-40fb-b10d-ed5892b76629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTunedModel(\n",
       "  (backbone): RoBertaModelCustom2(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Linear(in_features=300, out_features=768, bias=True)\n",
       "        (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (output_layer): Linear(in_features=768, out_features=300, bias=True)\n",
       "  )\n",
       "  (new_head): Linear(in_features=300, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FineTunedModel(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super(FineTunedModel, self).__init__()\n",
    "        self.backbone = backbone  # 事前学習済みモデル\n",
    "        self.new_head = nn.Linear(300, num_classes)  # 分類用の新しい出力層\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)  # (batch_size, seq_len, 3)\n",
    "        x = x.mean(dim=1)  # 時系列方向で平均化 (seq_len方向)\n",
    "        x = self.new_head(x)  # 分類用出力\n",
    "        return x\n",
    "\n",
    "# モデルを修正\n",
    "fine_tuned_model = FineTunedModel(model, num_classes=num_classes)\n",
    "fine_tuned_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf702f39-5c76-49f2-afde-75954c948e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45868/3962539304.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self._data[idx], dtype=torch.float32), torch.tensor(self._labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.2751, valid Loss: 1.0621811151504517, Accuracy: 47.78%, Val Accuracy: 57.84%\n",
      "Epoch 2/50, Loss: 0.8518, valid Loss: 0.9127974510192871, Accuracy: 62.81%, Val Accuracy: 60.78%\n",
      "Epoch 3/50, Loss: 0.6812, valid Loss: 0.6832645535469055, Accuracy: 75.12%, Val Accuracy: 72.55%\n",
      "Epoch 4/50, Loss: 0.5366, valid Loss: 0.7894772887229919, Accuracy: 81.53%, Val Accuracy: 73.53%\n",
      "Epoch 5/50, Loss: 0.4874, valid Loss: 0.7972719073295593, Accuracy: 82.27%, Val Accuracy: 76.47%\n",
      "Epoch 6/50, Loss: 0.4429, valid Loss: 0.7207929491996765, Accuracy: 82.27%, Val Accuracy: 74.51%\n",
      "Epoch 7/50, Loss: 0.3693, valid Loss: 0.6138863563537598, Accuracy: 86.45%, Val Accuracy: 82.35%\n",
      "Epoch 8/50, Loss: 0.3056, valid Loss: 0.6594995260238647, Accuracy: 89.16%, Val Accuracy: 80.39%\n",
      "Epoch 9/50, Loss: 0.2741, valid Loss: 0.6692320108413696, Accuracy: 90.64%, Val Accuracy: 76.47%\n",
      "Epoch 10/50, Loss: 0.2595, valid Loss: 0.8078792691230774, Accuracy: 89.66%, Val Accuracy: 77.45%\n",
      "Epoch 11/50, Loss: 0.1907, valid Loss: 0.7441690564155579, Accuracy: 93.35%, Val Accuracy: 79.41%\n",
      "Epoch 12/50, Loss: 0.1671, valid Loss: 1.002830147743225, Accuracy: 94.33%, Val Accuracy: 77.45%\n",
      "Epoch 13/50, Loss: 0.1320, valid Loss: 0.9664044380187988, Accuracy: 95.57%, Val Accuracy: 78.43%\n",
      "Epoch 14/50, Loss: 0.1328, valid Loss: 0.9708563089370728, Accuracy: 95.07%, Val Accuracy: 72.55%\n",
      "Epoch 15/50, Loss: 0.1398, valid Loss: 0.902773916721344, Accuracy: 94.09%, Val Accuracy: 76.47%\n",
      "Epoch 16/50, Loss: 0.2347, valid Loss: 0.957439124584198, Accuracy: 91.13%, Val Accuracy: 78.43%\n",
      "Epoch 17/50, Loss: 0.1985, valid Loss: 0.7524463534355164, Accuracy: 93.60%, Val Accuracy: 80.39%\n",
      "Epoch 18/50, Loss: 0.1191, valid Loss: 1.1430253982543945, Accuracy: 96.80%, Val Accuracy: 70.59%\n",
      "Epoch 19/50, Loss: 0.1000, valid Loss: 1.605608582496643, Accuracy: 97.29%, Val Accuracy: 80.39%\n",
      "Epoch 20/50, Loss: 0.1012, valid Loss: 1.113481879234314, Accuracy: 96.06%, Val Accuracy: 73.53%\n",
      "Epoch 21/50, Loss: 0.0966, valid Loss: 0.9160599112510681, Accuracy: 97.54%, Val Accuracy: 73.53%\n",
      "Epoch 22/50, Loss: 0.0469, valid Loss: 1.3057734966278076, Accuracy: 99.51%, Val Accuracy: 77.45%\n",
      "Epoch 23/50, Loss: 0.0322, valid Loss: 1.183424472808838, Accuracy: 99.26%, Val Accuracy: 77.45%\n",
      "Epoch 24/50, Loss: 0.0309, valid Loss: 1.3625779151916504, Accuracy: 99.26%, Val Accuracy: 77.45%\n",
      "Epoch 25/50, Loss: 0.0193, valid Loss: 1.2930153608322144, Accuracy: 100.00%, Val Accuracy: 73.53%\n",
      "Epoch 26/50, Loss: 0.0155, valid Loss: 1.2729640007019043, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 27/50, Loss: 0.0105, valid Loss: 1.2187625169754028, Accuracy: 100.00%, Val Accuracy: 78.43%\n",
      "Epoch 28/50, Loss: 0.0091, valid Loss: 1.2260613441467285, Accuracy: 100.00%, Val Accuracy: 77.45%\n",
      "Epoch 29/50, Loss: 0.0088, valid Loss: 1.2563482522964478, Accuracy: 100.00%, Val Accuracy: 75.49%\n",
      "Epoch 30/50, Loss: 0.0102, valid Loss: 1.2435497045516968, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 31/50, Loss: 0.0102, valid Loss: 1.215804100036621, Accuracy: 100.00%, Val Accuracy: 76.47%\n",
      "Epoch 32/50, Loss: 0.0105, valid Loss: 1.2385214567184448, Accuracy: 100.00%, Val Accuracy: 75.49%\n",
      "Epoch 33/50, Loss: 0.0108, valid Loss: 1.2340257167816162, Accuracy: 100.00%, Val Accuracy: 73.53%\n",
      "Epoch 34/50, Loss: 0.0112, valid Loss: 1.2464617490768433, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 35/50, Loss: 0.0109, valid Loss: 1.271818995475769, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 36/50, Loss: 0.0103, valid Loss: 1.2990726232528687, Accuracy: 100.00%, Val Accuracy: 73.53%\n",
      "Epoch 37/50, Loss: 0.0101, valid Loss: 1.3085525035858154, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 38/50, Loss: 0.0110, valid Loss: 1.2993358373641968, Accuracy: 100.00%, Val Accuracy: 73.53%\n",
      "Epoch 39/50, Loss: 0.0102, valid Loss: 1.322996973991394, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 40/50, Loss: 0.0101, valid Loss: 1.3367748260498047, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 41/50, Loss: 0.0103, valid Loss: 1.3249953985214233, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 42/50, Loss: 0.0102, valid Loss: 1.33310067653656, Accuracy: 100.00%, Val Accuracy: 74.51%\n",
      "Epoch 43/50, Loss: 0.0101, valid Loss: 1.3814629316329956, Accuracy: 100.00%, Val Accuracy: 75.49%\n",
      "Epoch 44/50, Loss: 0.0107, valid Loss: 1.4027491807937622, Accuracy: 100.00%, Val Accuracy: 73.53%\n",
      "Epoch 45/50, Loss: 0.0134, valid Loss: 1.3216968774795532, Accuracy: 100.00%, Val Accuracy: 67.65%\n",
      "Epoch 46/50, Loss: 0.0156, valid Loss: 1.544694185256958, Accuracy: 100.00%, Val Accuracy: 70.59%\n",
      "Epoch 47/50, Loss: 0.0119, valid Loss: 1.517062783241272, Accuracy: 100.00%, Val Accuracy: 71.57%\n",
      "Epoch 48/50, Loss: 0.0093, valid Loss: 1.6011683940887451, Accuracy: 100.00%, Val Accuracy: 72.55%\n",
      "Epoch 49/50, Loss: 0.0101, valid Loss: 1.4274814128875732, Accuracy: 100.00%, Val Accuracy: 70.59%\n",
      "Epoch 50/50, Loss: 0.0299, valid Loss: 1.505553126335144, Accuracy: 99.75%, Val Accuracy: 73.53%\n",
      "Best model reloaded with valid loss:  tensor(0.6139, device='cuda:0')   time: 7\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(fine_tuned_model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 50\n",
    "fine_tuned_model.train()\n",
    "\n",
    "train_loss = []\n",
    "validation_losses = []\n",
    "best_valid_loss = float('inf')\n",
    "best_model_path = 'best_model_downstream_adl_robert.pth'\n",
    "\n",
    "time_epoch = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    total_val_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 順伝播\n",
    "       \n",
    "        outputs = fine_tuned_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 逆伝播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 統計\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss.append(total_loss / len(train_loader))\n",
    "    fine_tuned_model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for val_inputs, val_targets in val_loader:\n",
    "            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "            val_outputs = fine_tuned_model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_targets)\n",
    "            val_loss += val_loss.item()\n",
    "            \n",
    "            # 統計\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_total += val_targets.size(0)\n",
    "            val_correct += (val_predicted == val_targets).sum().item()\n",
    "            \n",
    "        if val_loss < best_valid_loss:\n",
    "            best_valid_loss = val_loss\n",
    "            torch.save(fine_tuned_model.state_dict(), best_model_path)\n",
    "            time_epoch = epoch + 1\n",
    "    validation_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}, valid Loss: {val_loss / len(val_loader)}, Accuracy: {100 * correct / total:.2f}%, Val Accuracy: {100 * val_correct / val_total:.2f}%\")\n",
    "fine_tuned_model.load_state_dict(torch.load(best_model_path))\n",
    "print(\"Best model reloaded with valid loss: \", best_valid_loss/ len(val_loader), f\"  time: {time_epoch}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe5f63e-dc5b-44de-a38b-1febaec0e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = []\n",
    "for i in range(num_epochs):\n",
    "    value = validation_losses[i].item()\n",
    "    val_loss.append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c397e96-1741-46d5-bb61-f66af1a663d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss, color='C0', label='train loss')\n",
    "ax.plot(val_loss, color='C1', label='valid loss')\n",
    "\n",
    "ax.set_ylabel('loss (CE)')\n",
    "ax.set_xlabel('epoch')\n",
    "\n",
    "# 二軸グラフの追加\n",
    "ax2 = ax.twinx()\n",
    "ax2.grid(True)\n",
    "\n",
    "# 凡例の表示\n",
    "fig.legend(loc='upper right')\n",
    "\n",
    "# グラフの表示\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a1dd8dc-4da7-4527-a581-07cb062489a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.04%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18        10\n",
      "           1       0.86      1.00      0.93        25\n",
      "           2       0.70      0.74      0.72        19\n",
      "           3       1.00      0.86      0.93        22\n",
      "           4       0.84      0.96      0.90        51\n",
      "\n",
      "    accuracy                           0.85       127\n",
      "   macro avg       0.88      0.73      0.73       127\n",
      "weighted avg       0.87      0.85      0.83       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45868/3962539304.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self._data[idx], dtype=torch.float32), torch.tensor(self._labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "          \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return test_accuracy, all_preds, all_labels\n",
    "\n",
    "\n",
    "test_accuracy, test_preds, test_labels = evaluate_model(fine_tuned_model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ccf40d-87b4-47ec-a2e3-5658544d3c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
